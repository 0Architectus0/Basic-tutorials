{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple 10-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warkings (gets rid of some type-conversion warnings)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 10\n",
    "data = np.zeros((1000, 100))\n",
    "labels = np.zeros((1000, 1), dtype=int)\n",
    "\n",
    "poles = np.round(np.concatenate(\n",
    "    (np.random.uniform(0,classes,(classes,2)),\n",
    "    np.random.uniform(-5,5,(classes,4))),axis=1))\n",
    "\n",
    "#Using the poles, generate 100 images for each of them.\n",
    "points = 5000\n",
    "fig=plt.figure(figsize=(15, 7))\n",
    "for i in range(0, len(poles)):\n",
    "    p = poles[i,0:2]\n",
    "    for j in range(0,100):\n",
    "        sigma = poles[i, 2:6].reshape(2,2) + np.random.uniform(-0.5,0.5,(2,2))\n",
    "        x,y = np.random.multivariate_normal(p,sigma,points).T\n",
    "        H = np.histogram2d(x,y,bins=classes, range=[[0,classes],[0,classes]], normed=True)[0].T\n",
    "        data[i*100+j] = H.reshape(1,100)\n",
    "        labels[i*100+j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Visualization of the data\n",
    "This is not part of the Keras example, but it helps to understand what we are trying to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a 2D representation of the data, using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "data_viz = TSNE(n_components=2).fit_transform(data)\n",
    "print(\"Data dimensions after reduction: {}\".format(data_viz.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_viz[:,0], data_viz[:,1], c=labels[:,0], cmap=plt.cm.get_cmap(\"jet\", classes))\n",
    "plt.colorbar(ticks=range(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what each example looks like\n",
    "We can think of them as the images of \"digits.\" We will actually train character recognition in future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 10\n",
    "samples = np.array(range(0,1000,100)) + np.random.randint(0,100,(1,classes))\n",
    "samples = samples[0,:].tolist()\n",
    "\n",
    "fig=plt.figure(figsize=(15, 8))\n",
    "for i in range(0, sampleSize):\n",
    "    fig.add_subplot(2, 5, i+1, aspect='equal')\n",
    "    plt.imshow(np.reshape(data[samples[i],:], (10,10)), interpolation='nearest', cmap=\"hot\", origin='low')\n",
    "    plt.title('Class {}\\n({},{})'.format(labels[samples[i]], \n",
    "                                        poles[labels[samples[i]], 0].astype(int), \n",
    "                                        poles[labels[samples[i]], 1].astype(int)))\n",
    "    plt.xlabel(\"Img {}\".format(samples[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, let's use Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform labels (i.e., the outputs), to the shape expected by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=classes)\n",
    "\n",
    "# Optional: visualize the label transformation\n",
    "rIdx = np.random.randint(0, labels.shape[0])\n",
    "print(\"Label shapes before: {}\".format(labels.shape))\n",
    "print(\"\\tLabel at random index {}:\\n\\t{}\\n\".format(rIdx, labels[rIdx]))\n",
    "\n",
    "print(\"Label shapes after: {}\".format(one_hot_labels.shape))\n",
    "print(\"\\tOne-hot encoded label at random index {} (same as above):\\n\\t{}\\n\".format(rIdx, one_hot_labels[rIdx, :]))\n",
    "print(\"(Pos.)\\t{}\".format(np.array(range(0,10),dtype=\"float\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Note how the loss decreases, while the accuracy increases, as the training goes through more and more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=100, batch_size=32, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSetSize = 10\n",
    "predData = np.zeros((predSetSize, 100))\n",
    "samples = np.random.permutation(poles.shape[0])[0:predSetSize].tolist()\n",
    "\n",
    "for i in range(0, len(samples)):\n",
    "    p = poles[samples[i],0:2]\n",
    "    sigma = poles[samples[i], 2:6].reshape(2,2) + np.random.uniform(-0.5,0.5,(2,2))\n",
    "    x,y = np.random.multivariate_normal(p,sigma,points).T\n",
    "    H = np.histogram2d(x,y,bins=classes, range=[[0,classes],[0,classes]], normed=True)[0].T\n",
    "    predData[i] = H.reshape(1,100)\n",
    "\n",
    "results = np.round(model.predict(predData, verbose=1), decimals=2)\n",
    "resultLabels = np.argmax(results, axis=1)\n",
    "\n",
    "fig=plt.figure(figsize=(15, 8))\n",
    "for i in range(0, predSetSize):\n",
    "    fig.add_subplot(2,5, i+1)\n",
    "    plt.imshow(np.reshape(predData[i], (10,10)), interpolation='nearest', cmap=\"hot\", origin='low')\n",
    "    plt.title('Class {}\\n({},{})'.format(resultLabels[i], poles[resultLabels[i],0].astype(int), poles[resultLabels[i],1].astype(int)))\n",
    "    plt.xlabel(\"Img {}\".format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "This example is still abstract (i.e., we used random data), but it shows the general workflow. In the next tutorial, we will apply this to a meaningful dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
